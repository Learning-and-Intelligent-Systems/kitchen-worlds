#!/usr/bin/env python

from __future__ import print_function

import math
import argparse
import itertools
import shutil
import pickle
import os
import time
import random
import copy
import json
from os.path import join, abspath, dirname, isdir, isfile, basename
from config import EXP_PATH, OUTPUT_PATH
from itertools import product
from PIL import Image


# from pddlstream.language.constants import Equal, AND, print_solution, PDDLProblem
# from pddlstream.algorithms.meta import solve, create_parser

from pybullet_tools.utils import disconnect, LockRenderer, has_gui, WorldSaver, wait_if_gui, \
    SEPARATOR, get_aabb, wait_for_duration, has_gui, reset_simulation, set_random_seed, \
    set_numpy_seed, set_renderer
from pybullet_tools.bullet_utils import summarize_facts, print_goal, nice, get_datetime
from pybullet_tools.pr2_agent import solve_multiple, post_process, pddlstream_from_state_goal, \
    create_cwd_saver, solve_one
from pybullet_tools.pr2_primitives import control_commands, apply_commands
from pybullet_tools.logging import parallel_print, myprint

from lisdf_tools.lisdf_loader import pddl_files_from_dir

from world_builder.world import State
from world_builder.actions import apply_actions
from world_builder.world_generator import save_to_outputs_folder

from test_utils import parallel_processing, get_config
from test_world_builder import create_pybullet_world

from nsplan_tools.generate_semantic_specification import get_semantic_specs, get_semantic_spec
from nsplan_tools.utils.file import print_data_types

# additional dependencies for using streams
from pybullet_tools.bullet_utils import set_camera_target_body, visualize_camera_image, get_readable_list
from pybullet_planning.pybullet_tools.utils import get_image_at_pose, get_image, unit_pose, get_camera_matrix
import matplotlib.pyplot as plt
from world_builder.entities import StaticCamera
from world_builder.utils import parse_yaml
from pybullet_tools.pr2_primitives import Pose, Conf
from pybullet_tools.utils import get_pose, multiply, quat_from_euler, dump_world, get_bodies, remove_body, get_bodies, remove_body, invert, Euler, Point, pairwise_collisions, tform_from_pose, pose_from_tform
from pybullet_tools.flying_gripper_utils import get_se3_joints, se3_from_pose, Grasp, se3_ik
from world_builder.actions import get_primitive_actions

# gym-related
import gymnasium as gym
from gymnasium import error, spaces, utils
from gymnasium.utils import seeding
import numpy as np

from collect_clean_dish_rollouts import plot_images, CleanDishEnvV1

from nsplan.data.dataset_sequence_multiview_v2 import load_cache_data_builder



def process(input):
    """ exist a version in cognitive-architectures for generating mini-datasets (single process),
        run in kitchen-worlds for parallelization, but no reliable planning time data

        inside each data folder, to be generated:
        - before planning:
            [x] scene.lisdf
            [x] problem.pddl
            [x] planning_config.json
            [x] log.txt (generated before planning)
        - after planning:
            [x] plan.json
            [x] commands.pkl
            [x] log.json (generated by pddlstream)
    """

    config, spec_seed, env_seed = input

    new_config = copy.deepcopy(config)
    new_config.seed = env_seed
    new_config.semantic_spec_seed = spec_seed

    seed = env_seed
    semantic_spec_seed = spec_seed

    set_random_seed(seed)
    set_numpy_seed(seed)

    exp_dir = abspath(join(config.data.out_dir, "semantic_spec_{}_seed_{}".format(semantic_spec_seed, seed))) #+ get_datetime(TO_LISDF=True)))
    print("Generate data for", exp_dir)
    os.makedirs(exp_dir, exist_ok=True)
    new_config.data.out_dir = exp_dir

    new_config.world.builder_kwargs["semantic_spec_file"] = os.path.join(config.semantic_specs_dir, f"{semantic_spec_seed}.json")

    """ STEP 1 -- GENERATE SCENES """
    world, goal = create_pybullet_world(new_config, SAVE_LISDF=False, SAVE_TESTCASE=True)

    # # --------------------------------
    # env = CleanDishEnvV1(world, goal, config, render_mode="human")
    # input("env initialized, next?")
    # play(env)

    # --------------------------------
    env = CleanDishEnvV1(world, goal, config, render_mode="bot")
    # option 1
    # data = random_simulate_bfs(env, max_depth=3, debug=False)
    # print("\n\n" + "=" * 100)
    # print("all states")
    # for d in data:
    #     print("\n" + "-" * 50)
    #     cur_obs, commands_so_far, current_g, symbolic_state, action_to_feasibility, depth = d
    #     print(cur_obs.rgbPixels)
    #     # img = Image.fromarray(cur_obs.rgbPixels, 'RGBA')
    #     # img.show()
    #     plt.imshow(cur_obs.rgbPixels)
    #     plt.show()
    #     print(f"depth: {depth}")
    #     for action in action_to_feasibility:
    #         print(f"{action}: {action_to_feasibility[action]}")
    #     input("next?")

    # --------------------------------
    # directly cache data
    cache_save_dir = os.path.dirname(config.data.out_dir)

    pcs_cache_data_builder = load_cache_data_builder(cache_save_dir, config.cache_data["pcs_config_file"])
    pc_cache_data_builder = load_cache_data_builder(cache_save_dir, config.cache_data["pc_config_file"])

    if new_config.bias_sink_actions:
        rollouts = random_rollouts_for_sink(env, max_depth=new_config.max_rollout_depth, max_rollouts=new_config.max_rollouts, debug=False, simple_data=True, pick_from_sink_prob=new_config.pick_from_sink_prob)
    else:
        rollouts = random_rollouts(env, max_depth=new_config.max_rollout_depth, max_rollouts=new_config.max_rollouts, debug=False, simple_data=True)

    # convert the world entity obj to a simple str so we don't have problem unpickle it
    obj_dict = copy.deepcopy(world.obj_dict)
    for obj in obj_dict:
        obj_dict[obj]["name"] = str(obj_dict[obj]["name"])

    data_dict = {"rollouts": rollouts, "obj_dict": obj_dict, "pybullet_idx_to_name": {b: world.BODY_TO_OBJECT[b].name for b in world.BODY_TO_OBJECT}}
    pcs_cache_data_builder.cache_datum(data_dict, save_filename=f"semantic_spec_{semantic_spec_seed}_seed_{seed}.pkl")
    pc_cache_data_builder.cache_datum(data_dict, save_filename=f"semantic_spec_{semantic_spec_seed}_seed_{seed}.pkl")

    reset_simulation()
    disconnect()
    return


def random_rollouts(env, max_depth=6, max_rollouts=10, debug=False, simple_data=True):
    text_actions = sorted(env.get_admissible_text_actions())
    if debug:
        print(f"{len(text_actions)} available actions: {text_actions}")

    rollouts = []
    for ri in range(max_rollouts):

        rollout = []

        obs, info = env.reset()

        # the format of each node in the search tree
        # TODO: also add action_so_far so we can trace
        commands_so_far = []
        current_g = None
        current_gp = None
        symbolic_state = None
        action_to_feasibility = {}
        depth = 0
        next_node = (obs, commands_so_far, current_g, current_gp, symbolic_state, action_to_feasibility, depth)
        next_action = None

        while True:

            (cur_obs, commands_so_far, current_g, current_gp, symbolic_state, action_to_feasibility, depth) = next_node
            if debug:
                print("\n\n" + "=" * 100)
                print(f"action leading to this state {next_action}")
                print("symbolic state: ", symbolic_state)
                print("action_to_feasibility: ", action_to_feasibility)
                print("depth: ", depth)
                # plt.imshow(cur_obs.rgbPixels)
                # plt.show()
                plot_images({view_name: Image.fromarray(cur_obs[view_name][0], 'RGBA') for view_name in cur_obs})
                # print((cur_obs, commands_so_far, current_g, symbolic_state, action_to_feasibility, depth))

            if depth >= max_depth:
                break

            # important: even for checking symbolic feasibility, we need to reset the env
            env.reset_to_state(commands_so_far, current_g, current_gp, symbolic_state)

            symbolic_feasible_text_actions = []
            for text_action in text_actions:
                symbolic_feasible = env.check_symbolic_action_feasibility(text_action[0], text_action[1], text_action[2])
                if not symbolic_feasible:
                    action_to_feasibility[text_action] = -1
                else:
                    symbolic_feasible_text_actions.append(text_action)
            if debug:
                print(f"{len(symbolic_feasible_text_actions)} symbolic feasible actions: {symbolic_feasible_text_actions}")

            candidate_next_nodes = []
            motion_feasible_text_actions = []  # bookkeeping
            for text_action in symbolic_feasible_text_actions:
                if debug:
                    print("\n" + "-"*25)
                    input(f"check motion feasibility for {text_action}")
                reset_obs, _ = env.reset_to_state(commands_so_far, current_g, current_gp, symbolic_state)
                # debug: make sure cur_obs is the same as reset_obs
                action = env.convert_text_to_action(text_action[0], text_action[1], text_action[2])
                new_obs, new_score, new_done, _, _ = env.step(action)
                if new_score == -1:
                    # not feasible
                    action_to_feasibility[text_action] = -1
                else:
                    if new_done:
                        action_to_feasibility[text_action] = 100
                    else:
                        action_to_feasibility[text_action] = 1
                    motion_feasible_text_actions.append(text_action)
                    # add new node to frontier
                    new_commands_so_far = env.commands_so_far
                    new_current_g = env.current_g
                    new_current_gp = env.current_gp
                    new_symbolic_state = env.symbolic_state
                    new_action_to_feasibility = {}
                    new_depth = depth + 1
                    new_node = (new_obs, new_commands_so_far, new_current_g, new_current_gp, new_symbolic_state, new_action_to_feasibility, new_depth)
                    candidate_next_nodes.append(new_node)

                if debug:
                    print(f"action_to_feasibility: {action_to_feasibility[text_action]}")
                    print(f"current_g: {current_g}")
                    print(f"current_gp: {current_gp}")
                    print(f"new_current_g: {env.current_g}")
                    print(f"new_current_gp: {env.current_gp}")
                    print(f"new_symbolic_state: {env.symbolic_state}")
                    input("next?")

            if debug:
                print(f"{len(motion_feasible_text_actions)} motion feasible actions: {motion_feasible_text_actions}")
                input("next node?")

            next_action = None
            if candidate_next_nodes:
                act_idx = np.random.randint(0, len(candidate_next_nodes))
                next_node = candidate_next_nodes[act_idx]
                next_action = motion_feasible_text_actions[act_idx]

            if simple_data:
                if current_g is not None:
                    current_g = current_g[2]
                rollout.append((cur_obs, symbolic_state, current_g, current_gp, action_to_feasibility, depth, next_action))
            else:
                rollout.append((cur_obs, commands_so_far, current_g, current_gp, symbolic_state, action_to_feasibility, depth, next_action))

            if not candidate_next_nodes:
                break

        rollouts.append(rollout)

    if debug:
        for ri, rollout in enumerate(rollouts):
            print("\n\n" + "=" * 100)
            print(f"rollout no.{ri}")
            for d in rollout:
                print("\n" + "-" * 50)
                if simple_data:
                    cur_obs, symbolic_state, current_g, current_gp, action_to_feasibility, depth, next_action = d
                    print(d)
                else:
                    cur_obs, commands_so_far, current_g, current_gp, symbolic_state, action_to_feasibility, depth, next_action = d
                # print(cur_obs.rgbPixels)
                # img = Image.fromarray(cur_obs.rgbPixels, 'RGBA')
                # img.show()
                plot_images({view_name: Image.fromarray(cur_obs[view_name][0], 'RGBA') for view_name in cur_obs})
                print(f"depth: {depth}")
                for action in action_to_feasibility:
                    print(f"{action}: {action_to_feasibility[action]}")
                print(f"next action: {next_action}")
                print(f"current_g: {current_g}")
                print(f"current_gp: {current_gp}")
                input("next?")

    # if True:
    #     for ri, rollout in enumerate(rollouts):
    #         print("\n\n" + "=" * 100)
    #         print(f"rollout no.{ri}")
    #         for d in rollout:
    #             print("\n" + "-" * 50)
    #             if simple_data:
    #                 cur_obs, symbolic_state, current_g, action_to_feasibility, depth, next_action = d
    #             else:
    #                 cur_obs, commands_so_far, current_g, symbolic_state, action_to_feasibility, depth, next_action = d
    #             print(f"next action: {next_action}")
    #             print(f"current_g: {current_g}")
    #             input("next?")

    return rollouts


def random_rollouts_for_sink(env, max_depth=6, max_rollouts=10, debug=False, simple_data=True, pick_from_sink_prob=0.5):

    assert 0 <= pick_from_sink_prob <= 1, f"pick_from_sink_prob {pick_from_sink_prob} must be between 0 and 1"

    text_actions = sorted(env.get_admissible_text_actions())
    if debug:
        print(f"{len(text_actions)} available actions: {text_actions}")

    rollouts = []
    for ri in range(max_rollouts):

        rollout = []

        obs, info = env.reset()

        # the format of each node in the search tree
        # TODO: also add action_so_far so we can trace
        commands_so_far = []
        current_g = None
        current_gp = None
        symbolic_state = None
        action_to_feasibility = {}
        depth = 0
        next_node = (obs, commands_so_far, current_g, current_gp, symbolic_state, action_to_feasibility, depth)
        next_action = None
        prev_action = None

        while True:

            (cur_obs, commands_so_far, current_g, current_gp, symbolic_state, action_to_feasibility, depth) = next_node
            if debug:
                print("\n\n" + "=" * 100)
                print(f"action leading to this state {next_action}")
                print("symbolic state: ", symbolic_state)
                print("action_to_feasibility: ", action_to_feasibility)
                print("depth: ", depth)
                # plt.imshow(cur_obs.rgbPixels)
                # plt.show()
                plot_images({view_name: Image.fromarray(cur_obs[view_name][0], 'RGBA') for view_name in cur_obs})
                # print((cur_obs, commands_so_far, current_g, symbolic_state, action_to_feasibility, depth))

            if depth >= max_depth:
                break

            # important: even for checking symbolic feasibility, we need to reset the env
            env.reset_to_state(commands_so_far, current_g, current_gp, symbolic_state)

            symbolic_feasible_text_actions = []
            for text_action in text_actions:
                symbolic_feasible = env.check_symbolic_action_feasibility(text_action[0], text_action[1], text_action[2])
                if not symbolic_feasible:
                    action_to_feasibility[text_action] = -1
                else:
                    symbolic_feasible_text_actions.append(text_action)
            if debug:
                print(f"{len(symbolic_feasible_text_actions)} symbolic feasible actions: {symbolic_feasible_text_actions}")

            candidate_next_nodes = []
            motion_feasible_text_actions = []  # bookkeeping
            for text_action in symbolic_feasible_text_actions:
                if debug:
                    print("\n" + "-"*25)
                    input(f"check motion feasibility for {text_action}")
                reset_obs, _ = env.reset_to_state(commands_so_far, current_g, current_gp, symbolic_state)
                # debug: make sure cur_obs is the same as reset_obs
                action = env.convert_text_to_action(text_action[0], text_action[1], text_action[2])
                new_obs, new_score, new_done, _, _ = env.step(action)
                if new_score == -1:
                    # not feasible
                    action_to_feasibility[text_action] = -1
                else:
                    if new_done:
                        action_to_feasibility[text_action] = 100
                    else:
                        action_to_feasibility[text_action] = 1
                    # add new node to frontier
                    new_commands_so_far = env.commands_so_far
                    new_current_g = env.current_g
                    new_current_gp = env.current_gp
                    new_symbolic_state = env.symbolic_state
                    new_action_to_feasibility = {}
                    new_depth = depth + 1
                    new_node = (new_obs, new_commands_so_far, new_current_g, new_current_gp, new_symbolic_state, new_action_to_feasibility, new_depth)
                    motion_feasible_text_actions.append(text_action)
                    candidate_next_nodes.append(new_node)

                if debug:
                    print(f"action_to_feasibility: {action_to_feasibility[text_action]}")
                    print(f"current_g: {current_g}")
                    print(f"current_gp: {current_gp}")
                    print(f"new_current_g: {env.current_g}")
                    print(f"new_current_gp: {env.current_gp}")
                    print(f"new_symbolic_state: {env.symbolic_state}")
                    input("next?")

            if debug:
                print(f"{len(motion_feasible_text_actions)} motion feasible actions: {motion_feasible_text_actions}")
                input("next node?")

            prev_action = next_action
            next_action = None
            if candidate_next_nodes:

                # motion_feasible_text_actions stores the text actions that are motion feasible
                # manip, obj, loc = text_action

                sink_action_idxs = []
                other_action_idxs = []
                for ai, text_action in enumerate(motion_feasible_text_actions):
                    if text_action[2] == "sink_bottom":
                        sink_action_idxs.append(ai)
                    else:
                        other_action_idxs.append(ai)

                act_idx = None
                if motion_feasible_text_actions[0][0] == "pick":
                    # if there is a sink action, pick that with 50% chance (if there are other actions, pick one of them with 50% chance)
                    # if there is no sink action, pick one of the other actions
                    if sink_action_idxs:
                        if np.random.random() < pick_from_sink_prob or not other_action_idxs:
                            act_idx = np.random.choice(sink_action_idxs)
                    if act_idx is None:
                        act_idx = np.random.choice(other_action_idxs)
                else:
                    # if the object is picked from sink, move it out of sink
                    # if the object is not picked from sink, move it into sink if possible
                    assert prev_action is not None, "prev_action is None but the current action is not pick"
                    if prev_action[2] == "sink_bottom" and other_action_idxs:
                        act_idx = np.random.choice(other_action_idxs)
                    if act_idx is None:
                        if sink_action_idxs:
                            act_idx = np.random.choice(sink_action_idxs)
                        else:
                            act_idx = np.random.choice(other_action_idxs)

                next_node = candidate_next_nodes[act_idx]
                next_action = motion_feasible_text_actions[act_idx]

            if simple_data:
                if current_g is not None:
                    current_g = current_g[2]
                rollout.append((cur_obs, symbolic_state, current_g, current_gp, action_to_feasibility, depth, next_action))
            else:
                rollout.append((cur_obs, commands_so_far, current_g, current_gp, symbolic_state, action_to_feasibility, depth, next_action))

            if not candidate_next_nodes:
                break

        rollouts.append(rollout)

    if debug:
        for ri, rollout in enumerate(rollouts):
            print("\n\n" + "=" * 100)
            print(f"rollout no.{ri}")
            for d in rollout:
                print("\n" + "-" * 50)
                if simple_data:
                    cur_obs, symbolic_state, current_g, current_gp, action_to_feasibility, depth, next_action = d
                    print(d)
                else:
                    cur_obs, commands_so_far, current_g, current_gp, symbolic_state, action_to_feasibility, depth, next_action = d
                # print(cur_obs.rgbPixels)
                # img = Image.fromarray(cur_obs.rgbPixels, 'RGBA')
                # img.show()
                plot_images({view_name: Image.fromarray(cur_obs[view_name][0], 'RGBA') for view_name in cur_obs})
                print(f"depth: {depth}")
                for action in action_to_feasibility:
                    print(f"{action}: {action_to_feasibility[action]}")
                print(f"next action: {next_action}")
                print(f"current_g: {current_g}")
                print(f"current_gp: {current_gp}")
                input("next?")

    # if True:
    #     for ri, rollout in enumerate(rollouts):
    #         print("\n\n" + "=" * 100)
    #         print(f"rollout no.{ri}")
    #         for d in rollout:
    #             print("\n" + "-" * 50)
    #             if simple_data:
    #                 cur_obs, symbolic_state, current_g, action_to_feasibility, depth, next_action = d
    #             else:
    #                 cur_obs, commands_so_far, current_g, symbolic_state, action_to_feasibility, depth, next_action = d
    #             print(f"next action: {next_action}")
    #             print(f"current_g: {current_g}")
    #             input("next?")

    return rollouts


def collect_for_fastamp(config, args):

    inputs = []
    for spec_seed in range(args.semantic_spec_seed_start, args.semantic_spec_seed_start + args.num_semantic_spec_seed):
        env_seeds = np.random.choice(range(args.random_seed_start, args.random_seed_end), args.num_seed, replace=False)
        for env_seed in env_seeds:
            new_config = copy.deepcopy(config)
            # new_config.semantic_spec_seed = spec_seed
            # new_config.seed = env_seed
            inputs.append((new_config, spec_seed, env_seed))

    parallel_processing(process, inputs, parallel=config.parallel)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="collect rollouts")
    parser.add_argument("--random_seed_start", default=0, type=int)
    parser.add_argument("--random_seed_end", default=10000, type=int)
    parser.add_argument("--num_seed", default=10, type=int)
    parser.add_argument("--semantic_spec_seed_start", default=0, type=int)
    parser.add_argument("--num_semantic_spec_seed", default=10, type=int)
    parser.add_argument("--config_file", default='../configs/clean_dish_feg_collect_rollouts_parallel_sink.yaml', type=str)
    args = parser.parse_args()

    config = parse_yaml(args.config_file)
    collect_for_fastamp(config, args)

